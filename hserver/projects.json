{
  "projects": [
    {
      "summary": {
        "title": "Beatspeak",
        "imageSrc": "/assets/gifs/Beatspeak.gif",
        "overview": "This is a remote heartrate sensing C++ application that uses head movement to filter a users heartrate from a video source. The system is a collection of custom algorithms written in C++ and tuned using Bayesian Optimization",
        "additionalInfo": ""
      },
      "name": "Beatspeak",
      "details": {
        "additionalInfo": "Recently, the use of supervised learning has improved system performance, making it more efficient in noise handling. Efforts are ongoing to prepare Beatspeak for open-sourcing.",
        "imageSrc": "/assets/gifs/Beatspeak.gif",
        "title": "Beatspeak",
        "overview": "This project began in college as a wearable sensor and has evolved into a non-contact version using MIT research principles. It incorporates OpenCV in a multithreaded environment, blending digital signal processing with linear algebra.The project is basically applied singal processing in the form of a modern C++ multithreaded application. The key challenge is in getting high accuracy in most cases (and know when its low accuracy), the accuracy has to be achieved in a computationally effective way as my vision for this is something that runs on any smart phone.",
        "conclusion": "The sensor is just the first part of this, hopefully a reliable source of heartrate data will open up application in diagnosis, prevention and health insight using the latest trends in ML and datas science. This may require adding more metrics to monitor like body heat, respiration rate or other forms of movement that can be tracked using the same core algorihtms implemented for the HR"
      },
      "icon": "fas fa-heart-pulse text-blue-800 text-5xl"
    },
    {
      "summary": {
        "overview": "This is a web crawler(Damhan Alla is the Irish for spider) i built in Haskell and knowledge extractor created in a mixture of python and C++. The minded data is processed using a plethora of ML techniques and models",
        "title": "Damhan",
        "imageSrc": "/assets/gifs/Driocht.gif",
        "additionalInfo": ""
      },
      "name": "Damhan",
      "details": {
        "additionalInfo": "The idea is quite simple, I want to be able to point to a website or public record and have the crawler pull all the information from these sources. The idea is that relevant sites will be linked to each other, via references and other qoutes, while there will be divergence due to advertising etc this will be filtered out later, also advertisements are not as useless as they might first appear. Who chooses to advertise on these sites provides information of the local economy and target audience. Once the data is gathered and stored the next step is cleaning this is all done in Haskell with the results being saved to a Neo4j database and a postgress database. Once the data is cleaned python scripts are used with libraries like SpaCy to extract entities from the text and break it into part of speech (Noun, Adjective etc). With entities extracted we have a list of persons, places and things but these need to be related to each other in a logical way. Using K means clustering and TF indexing candities of related entities are gathered. Finally these pairs are feed to a Kernel Support Vector Machine I trained to classify if and what their relastionships are. The final data is loaded into Neo4j where the net of relationships can be seen. From here graph algorithms can be run to identify crucial nodes, key figures or even potential oppertunities",
        "title": "Damhan",
        "imageSrc": "/assets/pics/damhan.webp",
        "overview": "I built this crawler initially in Perl and then in Haskell, it starts with a list of sites and teh ethically crawls them, the crawler runs batches in parallel. It will take all links from the first generation and list them to be search in the next. The relationship between links is stored in a graph database. The content is stored in a raw from in an SQL database, the idea being to put a minimal load on crawled sites. ",
        "conclusion": "The real challenge in this is creating an efficient relationship classifier, I have experimented with transformer models like Bert but ultimately a SVM is best, however as this is a supervised method it requires labelled data. I have begun to gather this but until the kSVM performs with a 95% or greater accuracy im relying heavily on llama3 as a stand in. The LLM works really well but is not efficient, luckly however it is building up a training set to tain the kSVM on"
      },
      "icon": "fas fa-spider  text-blue-800 text-5xl"
    },
    {
      "summary": {
        "overview": "This is a programming language I created that is similar to C and lisp but in Gaeilge(Irish)",
        "title": "Driocht",
        "imageSrc": "/assets/gifs/Driocht.gif",
        "additionalInfo": ""
      },
      "name": "Driocht",
      "details": {
        "additionalInfo": "I created this because I was curious what it would be like to code in Irish, I think the language with its verb first structure lent it self well to coding",
        "title": "Driocht",
        "imageSrc": "/assets/gifs/Driocht.gif",
        "overview": "After getting a basic prototype working I havent done much with this, the main challenge being all development is done in English, its difficult to justify using a different langauge let alone create one. How ever recently I have been spening more time on this, there is definetly a place for it in rapid throw away scripts and personal procject. The speed up of having a custom written langauge can really add up",
        "conclusion": "Placeholder"
      },
      "icon": "fas fa-magic  text-blue-800 text-5xl"
    },
    {
      "icon": "fas fa-language text-blue-800 text-5xl",
      "details": {
        "additionalInfo": "Luckily because Irish was recognised as an official langauge of the EU the Parliment, which means there are thousands of documents publically available that were translated by professionals, I was able to use this and train a model over a week that performed quite well, it was compariable to google translate perforance in the early 2010s",
        "overview": "The core challenge of this Project was finding English and Irish sentence pairs, the Irish language is terrible under reasourced expeically on the web. Scrapping the content was the hardest part, expeically in doing it in a way with good quality",
        "title": "NMT",
        "imageSrc": "/assets/gifs/NMT.gif"
      },
      "name": "NMT",
      "summary": {
        "additionalInfo": "",
        "imageSrc": "/assets/gifs/NMT.gif",
        "title": "NMT",
        "overview": "This is a project that uses Neural Machine Translation techniques in C++ with scraping tools written in Haskell and perl to craete a translation mode for Gaeilge(Irish) to English and back",
        "conclusion": "Placeholder"
      }
    },
    {
      "summary": {
        "imageSrc": "/assets/gifs/Autonomous-Car.gif",
        "title": "Autonomous-Car",
        "overview": "I built this a few years ago to experiment and play with concepts in driverless cars",
        "additionalInfo": ""
      },
      "name": "Autonomous-Car",
      "icon": "fas fa-car text-blue-800 text-5xl",
      "details": {
        "title": "Autonomous-Car",
        "imageSrc": "/assets/gifs/Autonomous-Car.gif",
        "overview": "I built this shortly after my first drone to experiment and play with concepts in driverless cars",
        "additionalInfo": "The first iteration was simply an arduino conntected to ir sensors, then I added the raspberry pi and camera. The car can be controlled over wifi in manual or automated mode. I built a system that uses a kalmen filter with the ir sensors and camera for navigation. In the future I intend to attach a cheap 360 lidar I purchased to get realtime inforamtion on its environment. Ultimately I want to train up some deep reinforcement models and the ability to map environment so the car can opterate autonomously",
        "conclusion": "Placeholder"
      }
    },
    {
      "icon": "fas fa-helicopter text-blue-800 text-5xl",
      "details": {
        "additionalInfo": "I built the first drone with great difficulty using a CNC I had previously built and barely got it flying, following this I switch away from a modular system and used a raspberry pie with a quadcopter, i wrote cascading pid sensors to keep the drone in the air and then navigation software that used the gps with models trained in an unreal engine environment. A lot of what I did is available for free in arduino pilot and other open source projects. The point however was to learn and I think I achieved this. In the future id like to add the lidar.",
        "overview": "",
        "imageSrc": "/assets/gifs/Autonomous-Drone.gif",
        "title": "Autonomous-Drone"
      },
      "name": "Autonomous-Drone",
      "summary": {
        "imageSrc": "/assets/gifs/Autonomous-Drone.gif",
        "title": "Autonomous-Drone",
        "overview": "I began building a drone out of curiousity and have been adding to it over the years",
        "additionalInfo": "Placeholder",
        "conclusion": "Placeholde"
      }
    },
    {
      "icon": "fas fa-map-location text-blue-800 text-5xl",
      "details": {
        "title": "Autonomous-Navigation",
        "imageSrc": "/assets/gifs/Autonomous-Navigation.gif",
        "overview": "Autonomous-Navigation began as an innovative project and has evolved to incorporate advanced technologies and methodologies, demonstrating significant progress in its field.",
        "additionalInfo": "The approach I took was to use the gps signal with maps api to map out a route and rely on collision detection and rerouting to handle any issues that arouse. I used pathing algorithms, decission trees and kalmen filters. One approach I was pretty proud of was training on a virtual enviromant using unreal engine."
      },
      "name": "Autonomous-Navigation",
      "summary": {
        "additionalInfo": "Placeholder",
        "title": "Autonomous-Navigation",
        "imageSrc": "/assets/gifs/Autonomous-Navigation.gif",
        "overview": "With both the car and the drone, navigation because the most interesting application as it enables full autonomy. ",
        "conclusion": "Placeholder"
      }
    },
    {
      "summary": {
        "additionalInfo": "Placeholder",
        "overview": "For navigation, and with the drones and car the core challenge is detecting objections",
        "title": "Autonomous-Object-Detection",
        "imageSrc": "/assets/gifs/Autonomous-Object-Detection.gif"
      },
      "details": {
        "additionalInfo": "For this I used a variety of sensors from IR to Radar on the low cost side and from camera's to lidars on the more expensive side. The trick is setting them up to be reliable and figuring out how to combine the data, a kalmen filter works quite well. Even with good knowledge of the environment giving the systems good decision making abilities is hard, I started off with decission tress and moved into classic AI concepts. Now I am looking more and more into Deep reinforcement learning approaches",
        "overview": "Autonomous-Object-Detection began as an innovative project and has evolved to incorporate advanced technologies and methodologies, demonstrating significant progress in its field.",
        "title": "Autonomous-Object-Detection",
        "imageSrc": "/assets/gifs/Autonomous-Object-Detection.gif",
        "conclusion": "Placeholder"
      },
      "icon": "fas fa-eye-low-vision text-blue-800 text-5xl",
      "name": "Autonomous-Object-Detection"
    }
  ]
}
